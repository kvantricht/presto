{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13f47e98-297c-448d-b9ce-ad61bebec221",
   "metadata": {},
   "source": [
    "### First attempt to continue Presto pre-training on WorldCereal data\n",
    "\n",
    "Most code taken from https://github.com/nasaharvest/presto/blob/main/train.py, but only retained core parts to be able to test how Presto can eat the WorldCereal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f161c3be-3e4e-460e-a7e5-b8febf1b1e77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrieltseng/anaconda3/envs/lem/lib/python3.9/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, cast\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from presto import Presto\n",
    "from presto.dataops import BANDS_GROUPS_IDX, MASK_STRATEGIES\n",
    "\n",
    "\n",
    "from presto.model import LossWrapper, adjust_learning_rate, param_groups_weight_decay\n",
    "from presto.utils import (\n",
    "    DEFAULT_SEED,\n",
    "    config_dir,\n",
    "    device,\n",
    "    initialize_logging,\n",
    "    seed_everything,\n",
    "    timestamp_dirname,\n",
    "    update_data_dir,\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(\"__main__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db440dbb-8b2b-41fc-81ee-3e3dcd47dff6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26-10-2023 11:20:42 - INFO - Initialized logging to output/2023_10_26_11_20_42_680240/console-output.log\n",
      "26-10-2023 11:20:42 - INFO - Using output dir: output/2023_10_26_11_20_42_680240\n"
     ]
    }
   ],
   "source": [
    "model_name = 'presto_worldcereal'\n",
    "seed = DEFAULT_SEED\n",
    "seed_everything(seed)\n",
    "output_parent_dir = Path('.')\n",
    "run_id = None\n",
    "\n",
    "logging_dir = output_parent_dir / \"output\" / timestamp_dirname(run_id)\n",
    "logging_dir.mkdir(exist_ok=True, parents=True)\n",
    "initialize_logging(logging_dir)\n",
    "logger.info(\"Using output dir: %s\" % logging_dir)\n",
    "\n",
    "# Taken the defaults for now\n",
    "num_epochs = 20\n",
    "val_per_n_steps = 1000\n",
    "dynamic_world_loss_weight = 2  # Set to 0 if we don't have DW?\n",
    "max_learning_rate = 0.0001  # 0.001 is default, for finetuning max should be lower?\n",
    "min_learning_rate = 0\n",
    "warmup_epochs = 2\n",
    "weight_decay = 0.05\n",
    "batch_size = 2  # default 4096\n",
    "\n",
    "# Default mask strategies and mask_ratio\n",
    "mask_strategies = MASK_STRATEGIES\n",
    "mask_ratio: float = 0.75\n",
    "\n",
    "path_to_config = config_dir / \"default.json\"\n",
    "model_kwargs = json.load(Path(path_to_config).open(\"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db61b07-2788-44f7-91f5-53f7afa1675e",
   "metadata": {},
   "source": [
    "### Load a (very) small test dataframe from WorldCereal\n",
    "\n",
    "It's been reprocessed to match better Presto requirements, most notably:\n",
    "- monthly instead of 10-day compositing\n",
    "- outputing as 'features' the composited time series of all required bands instead of expert features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c58bc99f-3ac8-4a31-8e1c-a5ae4ffeedbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OPTICAL-B02-ts0-10m</th>\n",
       "      <th>OPTICAL-B02-ts1-10m</th>\n",
       "      <th>OPTICAL-B02-ts2-10m</th>\n",
       "      <th>OPTICAL-B02-ts3-10m</th>\n",
       "      <th>OPTICAL-B02-ts4-10m</th>\n",
       "      <th>OPTICAL-B02-ts5-10m</th>\n",
       "      <th>OPTICAL-B02-ts6-10m</th>\n",
       "      <th>OPTICAL-B02-ts7-10m</th>\n",
       "      <th>OPTICAL-B02-ts8-10m</th>\n",
       "      <th>OPTICAL-B02-ts9-10m</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>CT</th>\n",
       "      <th>OUTPUT</th>\n",
       "      <th>IRR</th>\n",
       "      <th>location_id</th>\n",
       "      <th>ref_id</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>aez_zoneid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>468</td>\n",
       "      <td>0</td>\n",
       "      <td>581</td>\n",
       "      <td>534</td>\n",
       "      <td>670</td>\n",
       "      <td>381</td>\n",
       "      <td>329</td>\n",
       "      <td>458</td>\n",
       "      <td>653</td>\n",
       "      <td>1261</td>\n",
       "      <td>...</td>\n",
       "      <td>50.897915</td>\n",
       "      <td>2.668585</td>\n",
       "      <td>1110</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0000280664EDE418</td>\n",
       "      <td>2018_BE_LPIS-Flanders</td>\n",
       "      <td>2017-10-27</td>\n",
       "      <td>2018-10-26</td>\n",
       "      <td>46172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>741</td>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "      <td>354</td>\n",
       "      <td>567</td>\n",
       "      <td>275</td>\n",
       "      <td>249</td>\n",
       "      <td>425</td>\n",
       "      <td>712</td>\n",
       "      <td>958</td>\n",
       "      <td>...</td>\n",
       "      <td>50.897903</td>\n",
       "      <td>2.664141</td>\n",
       "      <td>1510</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0000280664EDE418</td>\n",
       "      <td>2018_BE_LPIS-Flanders</td>\n",
       "      <td>2017-10-27</td>\n",
       "      <td>2018-10-26</td>\n",
       "      <td>46172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>359</td>\n",
       "      <td>5651</td>\n",
       "      <td>339</td>\n",
       "      <td>436</td>\n",
       "      <td>609</td>\n",
       "      <td>289</td>\n",
       "      <td>389</td>\n",
       "      <td>509</td>\n",
       "      <td>663</td>\n",
       "      <td>1100</td>\n",
       "      <td>...</td>\n",
       "      <td>50.893848</td>\n",
       "      <td>2.665414</td>\n",
       "      <td>1110</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0000280664EDE418</td>\n",
       "      <td>2018_BE_LPIS-Flanders</td>\n",
       "      <td>2017-10-27</td>\n",
       "      <td>2018-10-26</td>\n",
       "      <td>46172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>510</td>\n",
       "      <td>7468</td>\n",
       "      <td>518</td>\n",
       "      <td>516</td>\n",
       "      <td>781</td>\n",
       "      <td>1158</td>\n",
       "      <td>1008</td>\n",
       "      <td>1236</td>\n",
       "      <td>540</td>\n",
       "      <td>456</td>\n",
       "      <td>...</td>\n",
       "      <td>50.892136</td>\n",
       "      <td>2.660255</td>\n",
       "      <td>9520</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0000280664EDE418</td>\n",
       "      <td>2018_BE_LPIS-Flanders</td>\n",
       "      <td>2017-10-27</td>\n",
       "      <td>2018-10-26</td>\n",
       "      <td>46172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358</td>\n",
       "      <td>6283</td>\n",
       "      <td>389</td>\n",
       "      <td>453</td>\n",
       "      <td>719</td>\n",
       "      <td>1141</td>\n",
       "      <td>1141</td>\n",
       "      <td>758</td>\n",
       "      <td>587</td>\n",
       "      <td>484</td>\n",
       "      <td>...</td>\n",
       "      <td>50.892136</td>\n",
       "      <td>2.660255</td>\n",
       "      <td>9520</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0000280664EDE418</td>\n",
       "      <td>2018_BE_LPIS-Flanders</td>\n",
       "      <td>2017-10-27</td>\n",
       "      <td>2018-10-26</td>\n",
       "      <td>46172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   OPTICAL-B02-ts0-10m  OPTICAL-B02-ts1-10m  OPTICAL-B02-ts2-10m  \\\n",
       "0                  468                    0                  581   \n",
       "1                  741                    0                  267   \n",
       "2                  359                 5651                  339   \n",
       "3                  510                 7468                  518   \n",
       "4                  358                 6283                  389   \n",
       "\n",
       "   OPTICAL-B02-ts3-10m  OPTICAL-B02-ts4-10m  OPTICAL-B02-ts5-10m  \\\n",
       "0                  534                  670                  381   \n",
       "1                  354                  567                  275   \n",
       "2                  436                  609                  289   \n",
       "3                  516                  781                 1158   \n",
       "4                  453                  719                 1141   \n",
       "\n",
       "   OPTICAL-B02-ts6-10m  OPTICAL-B02-ts7-10m  OPTICAL-B02-ts8-10m  \\\n",
       "0                  329                  458                  653   \n",
       "1                  249                  425                  712   \n",
       "2                  389                  509                  663   \n",
       "3                 1008                 1236                  540   \n",
       "4                 1141                  758                  587   \n",
       "\n",
       "   OPTICAL-B02-ts9-10m  ...        lat       lon    CT  OUTPUT  IRR  \\\n",
       "0                 1261  ...  50.897915  2.668585  1110      11    0   \n",
       "1                  958  ...  50.897903  2.664141  1510      11    0   \n",
       "2                 1100  ...  50.893848  2.665414  1110      11    0   \n",
       "3                  456  ...  50.892136  2.660255  9520      12    0   \n",
       "4                  484  ...  50.892136  2.660255  9520      12    0   \n",
       "\n",
       "        location_id                 ref_id  start_date    end_date  aez_zoneid  \n",
       "0  0000280664EDE418  2018_BE_LPIS-Flanders  2017-10-27  2018-10-26       46172  \n",
       "1  0000280664EDE418  2018_BE_LPIS-Flanders  2017-10-27  2018-10-26       46172  \n",
       "2  0000280664EDE418  2018_BE_LPIS-Flanders  2017-10-27  2018-10-26       46172  \n",
       "3  0000280664EDE418  2018_BE_LPIS-Flanders  2017-10-27  2018-10-26       46172  \n",
       "4  0000280664EDE418  2018_BE_LPIS-Flanders  2017-10-27  2018-10-26       46172  \n",
       "\n",
       "[5 rows x 183 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('worldcereal_testdf.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9342bd0f-4b40-4c8f-ad50-5c594c148f5a",
   "metadata": {},
   "source": [
    "### Making WorldCereal data compatible for Presto\n",
    "\n",
    "Uses a `WorldCerealDataset` pytorch dataset that upon requesting an item performs the required conversions to Presto inputs.\n",
    "If `mask_params` is provided, inputs will get the shape of what Presto pretraining normally requires, including a generated `mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69fbccfe-8434-42d5-8f4f-086eca85267c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26-10-2023 11:20:42 - INFO - Setting up dataloaders\n"
     ]
    }
   ],
   "source": [
    "from ewoc_presto import WorldCerealDataset, MaskParamsNoDw\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "logger.info(\"Setting up dataloaders\")\n",
    "\n",
    "# Load the mask parameters\n",
    "mask_params = MaskParamsNoDw(mask_strategies, mask_ratio)\n",
    "\n",
    "# Create the WorldCereal dataset\n",
    "ds = WorldCerealDataset(df, mask_params=mask_params)\n",
    "\n",
    "# Create DataLoaders from the dataset. For now, without shame using same data for train and val\n",
    "# we're just testing functionality ;-)\n",
    "train_dataloader = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(ds, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a57b43-bb29-4f38-88b2-486dcbce52f2",
   "metadata": {},
   "source": [
    "Check what an item from this dataset looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8e7dc72-5b74-4b75-a3fa-05e28ef541e9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "group_bands\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MaskedExample(mask_eo=array([[ True,  True,  True,  True,  True, False, False, False, False,\n",
       "         True,  True,  True,  True,  True,  True,  True, False],\n",
       "       [ True,  True,  True,  True,  True, False, False, False, False,\n",
       "         True,  True,  True,  True,  True,  True,  True, False],\n",
       "       [ True,  True,  True,  True,  True, False, False, False, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False],\n",
       "       [ True,  True,  True,  True,  True, False, False, False,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True, False, False, False, False,\n",
       "         True,  True,  True,  True,  True,  True,  True, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True, False],\n",
       "       [ True,  True,  True,  True,  True, False, False, False, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True, False, False, False, False,\n",
       "         True,  True,  True,  True,  True,  True,  True, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False],\n",
       "       [ True,  True,  True,  True,  True, False, False, False, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True]]), mask_dw=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True]), x_eo=array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.1019    , 0.1503    , 0.166     , 0.1427    , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.3449576 ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.1346    , 0.1954    , 0.2099    , 0.2211    , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.228     , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.40958264],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.39922732],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.1041    , 0.2315    , 0.284     , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0976    , 0.2935    , 0.3797    , 0.3783    , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.794592  ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.409     , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.81214   ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.1725    , 0.2673    , 0.3199    , 0.3368    , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2005    , 0.257     , 0.279     , 0.3028    , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.25565   ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.31101024],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.1292    , 0.1477    , 0.1639    , 0.1638    , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ]], dtype=float32), y_eo=array([[7.1070445e-01, 4.0414044e-01, 4.6799999e-02, 6.3299999e-02,\n",
       "        6.9499999e-02, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 1.7900001e-01, 1.5350001e-01, 9.8899998e-02,\n",
       "        2.8600028e-01, 1.7580000e+00, 8.0000004e-03, 2.2097086e-04,\n",
       "        0.0000000e+00],\n",
       "       [7.6310456e-01, 4.4350997e-01, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.6571482e-01, 3.1013334e+00, 8.0000004e-03, 2.2097086e-04,\n",
       "        0.0000000e+00],\n",
       "       [7.7439803e-01, 4.4943887e-01, 5.8100000e-02, 8.9000002e-02,\n",
       "        1.0240000e-01, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 2.2900000e-01, 1.8320000e-01, 1.2630001e-01,\n",
       "        1.9371425e-01, 3.5703335e+00, 8.0000004e-03, 2.2097086e-04,\n",
       "        3.6692429e-01],\n",
       "       [7.4385452e-01, 4.0304527e-01, 5.3399999e-02, 8.3099999e-02,\n",
       "        9.5500000e-02, 1.3530000e-01, 2.0450000e-01, 2.2409999e-01,\n",
       "        0.0000000e+00, 2.4140000e-01, 1.7060000e-01, 1.0670000e-01,\n",
       "        1.2000035e-01, 1.4010000e+00, 8.0000004e-03, 2.2097086e-04,\n",
       "        0.0000000e+00],\n",
       "       [7.1858895e-01, 3.6650026e-01, 6.7000002e-02, 8.9900002e-02,\n",
       "        9.3300000e-02, 1.3800000e-01, 2.0850000e-01, 2.2849999e-01,\n",
       "        2.1730000e-01, 2.4770001e-01, 1.9509999e-01, 1.3169999e-01,\n",
       "        1.6885725e-01, 2.0913334e+00, 8.0000004e-03, 2.2097086e-04,\n",
       "        0.0000000e+00],\n",
       "       [6.9431806e-01, 3.9765644e-01, 3.8100000e-02, 6.5099999e-02,\n",
       "        5.4099999e-02, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        2.6800001e-01, 2.9820001e-01, 1.6370000e-01, 9.5500000e-02,\n",
       "        3.3199987e-01, 2.6080000e+00, 8.0000004e-03, 2.2097086e-04,\n",
       "        6.6407943e-01],\n",
       "       [4.8248756e-01, 3.1345016e-01, 3.2900002e-02, 6.3400000e-02,\n",
       "        4.3299999e-02, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 4.0000001e-01, 1.7080000e-01, 9.8600000e-02,\n",
       "        3.5657173e-01, 2.7900002e+00, 8.0000004e-03, 2.2097086e-04,\n",
       "        0.0000000e+00],\n",
       "       [5.0303054e-01, 3.1309509e-01, 4.5800000e-02, 6.2300000e-02,\n",
       "        4.2399999e-02, 8.6999997e-02, 2.9620001e-01, 4.1389999e-01,\n",
       "        0.0000000e+00, 4.4100001e-01, 1.5560000e-01, 7.7299997e-02,\n",
       "        4.9171403e-01, 8.6833334e-01, 8.0000004e-03, 2.2097086e-04,\n",
       "        0.0000000e+00],\n",
       "       [6.1433578e-01, 3.7268978e-01, 6.5300003e-02, 1.0580000e-01,\n",
       "        1.1890000e-01, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 3.6379999e-01, 2.0670000e-01, 1.2650000e-01,\n",
       "        5.7457191e-01, 1.8366668e-01, 8.0000004e-03, 2.2097086e-04,\n",
       "        4.7816548e-01],\n",
       "       [6.6410881e-01, 3.2872450e-01, 1.2610000e-01, 1.5770000e-01,\n",
       "        1.7950000e-01, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 3.0300000e-01, 3.0170000e-01, 2.2860000e-01,\n",
       "        5.9200001e-01, 2.0303335e+00, 8.0000004e-03, 2.2097086e-04,\n",
       "        0.0000000e+00],\n",
       "       [5.9743655e-01, 2.8575873e-01, 7.5400002e-02, 1.0820000e-01,\n",
       "        1.2140000e-01, 1.5680000e-01, 2.0370001e-01, 2.2139999e-01,\n",
       "        2.3100001e-01, 2.3649999e-01, 2.4150001e-01, 2.0400000e-01,\n",
       "        4.8828560e-01, 2.1930001e+00, 8.0000004e-03, 2.2097086e-04,\n",
       "        0.0000000e+00],\n",
       "       [5.5043799e-01, 2.3649834e-01, 5.7000000e-02, 8.2699999e-02,\n",
       "        9.9299997e-02, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 1.8080001e-01, 2.0950000e-01, 1.8629999e-01,\n",
       "        4.0114310e-01, 1.3730000e+00, 8.0000004e-03, 2.2097086e-04,\n",
       "        2.4515395e-01]], dtype=float32), x_dw=tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.]), y_dw=tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.]), start_month=tensor(9), latlon=tensor([50.8979,  2.6686]), strategy='group_bands')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad68850d-5c0d-4594-b4c6-0478b8e15163",
   "metadata": {},
   "source": [
    "### Setup Presto model and load pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1793713-09a7-4dd0-a7c0-30a7f4dd4d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26-10-2023 11:20:43 - INFO - Setting up model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Presto(\n",
       "  (encoder): Encoder(\n",
       "    (eo_patch_embed): ModuleDict(\n",
       "      (S1): Linear(in_features=2, out_features=128, bias=True)\n",
       "      (S2_RGB): Linear(in_features=3, out_features=128, bias=True)\n",
       "      (S2_Red_Edge): Linear(in_features=3, out_features=128, bias=True)\n",
       "      (S2_NIR_10m): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (S2_NIR_20m): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (S2_SWIR): Linear(in_features=2, out_features=128, bias=True)\n",
       "      (ERA5): Linear(in_features=2, out_features=128, bias=True)\n",
       "      (SRTM): Linear(in_features=2, out_features=128, bias=True)\n",
       "      (NDVI): Linear(in_features=1, out_features=128, bias=True)\n",
       "    )\n",
       "    (dw_embed): Embedding(10, 128)\n",
       "    (latlon_embed): Linear(in_features=3, out_features=128, bias=True)\n",
       "    (blocks): ModuleList(\n",
       "      (0-1): 2 x Block(\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (month_embed): Embedding(12, 32)\n",
       "    (channel_embed): Embedding(10, 32)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (decoder_embed): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (decoder_blocks): ModuleList(\n",
       "      (0-1): 2 x Block(\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (decoder_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (eo_decoder_pred): ModuleDict(\n",
       "      (S1): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (S2_RGB): Linear(in_features=128, out_features=3, bias=True)\n",
       "      (S2_Red_Edge): Linear(in_features=128, out_features=3, bias=True)\n",
       "      (S2_NIR_10m): Linear(in_features=128, out_features=1, bias=True)\n",
       "      (S2_NIR_20m): Linear(in_features=128, out_features=1, bias=True)\n",
       "      (S2_SWIR): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (ERA5): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (SRTM): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (NDVI): Linear(in_features=128, out_features=1, bias=True)\n",
       "    )\n",
       "    (dw_decoder_pred): Linear(in_features=128, out_features=9, bias=True)\n",
       "    (channel_embeddings): Embedding(10, 32)\n",
       "    (month_embed): Embedding(12, 48)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.info(\"Setting up model\")\n",
    "model = Presto.load_pretrained()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "814fc9c4-6eb0-4a19-be5e-796e56083563",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model hyperparameters: keep unchanged for now\n",
    "param_groups = param_groups_weight_decay(model, weight_decay)\n",
    "optimizer = optim.AdamW(param_groups, lr=max_learning_rate, betas=(0.9, 0.95))\n",
    "mse = LossWrapper(nn.MSELoss())\n",
    "ce = LossWrapper(nn.CrossEntropyLoss())\n",
    "\n",
    "training_config = {\n",
    "    \"model\": model.__class__,\n",
    "    \"encoder\": model.encoder.__class__,\n",
    "    \"decoder\": model.decoder.__class__,\n",
    "    \"optimizer\": optimizer.__class__.__name__,\n",
    "    \"eo_loss\": mse.loss.__class__.__name__,\n",
    "    \"dynamic_world_loss\": ce.loss.__class__.__name__,\n",
    "    \"device\": device,\n",
    "    \"logging_dir\": logging_dir,\n",
    "    # **args,\n",
    "    # **model_kwargs,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63c26b1-a10b-4101-909e-65edaaebfdc2",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "Copy from original code the relevant parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddfada35-31de-4e99-b2fb-014ba12eb5dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|                                                            | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train:   0%|                                                           | 0/250 [00:00<?, ?it/s]\u001b[A\n",
      "Train:   0%|▏                                                  | 1/250 [00:00<00:28,  8.67it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "group_bands\n",
      "72\n",
      "group_bands\n",
      "72\n",
      "group_bands\n",
      "72\n",
      "random_timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:   0%|                                                            | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "group_bands\n",
      "72\n",
      "chunk_timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "10752, 9856",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 30\u001b[0m\n\u001b[1;32m     21\u001b[0m lr \u001b[38;5;241m=\u001b[39m adjust_learning_rate(\n\u001b[1;32m     22\u001b[0m     optimizer,\n\u001b[1;32m     23\u001b[0m     epoch_step \u001b[38;5;241m/\u001b[39m dataloader_length \u001b[38;5;241m+\u001b[39m epoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     min_learning_rate,\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Get model outputs and calculate loss\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m y_pred, dw_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic_world\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_dw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatlons\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatlons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_month\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# set all SRTM timesteps except the first one to unmasked, so that\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# they will get ignored by the loss function even if the SRTM\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# value was masked\u001b[39;00m\n\u001b[1;32m     36\u001b[0m mask[:, \u001b[38;5;241m1\u001b[39m:, BANDS_GROUPS_IDX[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSRTM\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/lem/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/code/presto/presto/presto.py:729\u001b[0m, in \u001b[0;36mPresto.forward\u001b[0;34m(self, x, dynamic_world, latlons, mask, month)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    723\u001b[0m     x: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    727\u001b[0m     month: Union[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    728\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 729\u001b[0m     x, kept_indices, removed_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_world\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_world\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatlons\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatlons\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmonth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmonth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(x, kept_indices, removed_indices, month)\n",
      "File \u001b[0;32m~/anaconda3/envs/lem/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/code/presto/presto/presto.py:468\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x, dynamic_world, latlons, mask, month, eval_task)\u001b[0m\n\u001b[1;32m    466\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(all_tokens, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [batch, timesteps, embedding_dim]\u001b[39;00m\n\u001b[1;32m    467\u001b[0m mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(all_masks, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [batch, timesteps, embedding_dim]\u001b[39;00m\n\u001b[0;32m--> 468\u001b[0m x, kept_indices, removed_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# append latlon tokens\u001b[39;00m\n\u001b[1;32m    471\u001b[0m latlon_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatlon_embed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcartesian(latlons))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/code/presto/presto/presto.py:373\u001b[0m, in \u001b[0;36mEncoder.mask_tokens\u001b[0;34m(x, mask)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmask_tokens\u001b[39m(x, mask):\n\u001b[1;32m    370\u001b[0m     summed \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39msum(\n\u001b[1;32m    371\u001b[0m         dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    372\u001b[0m     )  \u001b[38;5;66;03m# summed tells me the number of masked elements per batch idx\u001b[39;00m\n\u001b[0;32m--> 373\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m summed\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m==\u001b[39m summed\u001b[38;5;241m.\u001b[39mmin(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msummed\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msummed\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    375\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    376\u001b[0m     removed_elements_per_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(summed\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m/\u001b[39m mask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])\n",
      "\u001b[0;31mAssertionError\u001b[0m: 10752, 9856"
     ]
    }
   ],
   "source": [
    "lowest_validation_loss = None\n",
    "best_val_epoch = 0\n",
    "training_step = 0\n",
    "num_validations = 0\n",
    "dataloader_length = df.shape[0]\n",
    "\n",
    "with tqdm(range(num_epochs), desc=\"Epoch\") as tqdm_epoch:\n",
    "    for epoch in tqdm_epoch:\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        # ------------------------ Training ----------------------------------------\n",
    "        total_eo_train_loss = 0.0\n",
    "        num_updates_being_captured = 0\n",
    "        train_size = 0\n",
    "        model.train()\n",
    "        for epoch_step, b in enumerate(tqdm(train_dataloader, desc=\"Train\", leave=False)):\n",
    "            mask, x, y, start_month = b[0].to(device), b[2].to(device), b[3].to(device), b[6]\n",
    "            dw_mask, x_dw, y_dw = b[1].to(device), b[4].to(device).long(), b[5].to(device).long()\n",
    "            latlons = b[7].to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            lr = adjust_learning_rate(\n",
    "                optimizer,\n",
    "                epoch_step / dataloader_length + epoch,\n",
    "                warmup_epochs,\n",
    "                num_epochs,\n",
    "                max_learning_rate,\n",
    "                min_learning_rate,\n",
    "            )\n",
    "            # Get model outputs and calculate loss\n",
    "            y_pred, dw_pred = model(\n",
    "                x, mask=mask, dynamic_world=x_dw, latlons=latlons, month=start_month\n",
    "            )\n",
    "            # set all SRTM timesteps except the first one to unmasked, so that\n",
    "            # they will get ignored by the loss function even if the SRTM\n",
    "            # value was masked\n",
    "            mask[:, 1:, BANDS_GROUPS_IDX[\"SRTM\"]] = False\n",
    "            loss = mse(y_pred[mask], y[mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            current_batch_size = len(x)\n",
    "            total_eo_train_loss += loss.item()\n",
    "            num_updates_being_captured += 1\n",
    "            train_size += current_batch_size\n",
    "            training_step += 1\n",
    "\n",
    "            # ------------------------ Validation --------------------------------------\n",
    "            if training_step % val_per_n_steps == 0:\n",
    "                total_eo_val_loss = 0.0\n",
    "                num_val_updates_captured = 0\n",
    "                val_size = 0\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    for b in tqdm(val_dataloader, desc=\"Validate\"):\n",
    "                        mask, x, y, start_month = (\n",
    "                            b[0].to(device),\n",
    "                            b[2].to(device),\n",
    "                            b[3].to(device),\n",
    "                            b[6],\n",
    "                        )\n",
    "                        dw_mask, x_dw = b[1].to(device), b[4].to(device).long()\n",
    "                        y_dw, latlons = b[5].to(device).long(), b[7].to(device)\n",
    "                        # Get model outputs and calculate loss\n",
    "                        y_pred, dw_pred = model(\n",
    "                            x, mask=mask, dynamic_world=x_dw, latlons=latlons, month=start_month\n",
    "                        )\n",
    "                        # set all SRTM timesteps except the first one to unmasked, so that\n",
    "                        # they will get ignored by the loss function even if the SRTM\n",
    "                        # value was masked\n",
    "                        mask[:, 1:, BANDS_GROUPS_IDX[\"SRTM\"]] = False\n",
    "                        loss = mse(y_pred[mask], y[mask])\n",
    "                        current_batch_size = len(x)\n",
    "                        total_eo_val_loss += loss.item()\n",
    "                        num_val_updates_captured += 1\n",
    "\n",
    "                # ------------------------ Metrics + Logging -------------------------------\n",
    "                # train_loss now reflects the value against which we calculate gradients\n",
    "                train_eo_loss = total_eo_train_loss / num_updates_being_captured\n",
    "                val_eo_loss = total_eo_val_loss / num_val_updates_captured\n",
    "\n",
    "                if \"train_size\" not in training_config and \"val_size\" not in training_config:\n",
    "                    training_config[\"train_size\"] = train_size\n",
    "                    training_config[\"val_size\"] = val_size\n",
    "                    if wandb_enabled:\n",
    "                        wandb.config.update(training_config)\n",
    "\n",
    "                to_log = {\n",
    "                    \"train_eo_loss\": train_eo_loss,\n",
    "                    \"val_eo_loss\": val_eo_loss,\n",
    "                    \"training_step\": training_step,\n",
    "                    \"epoch\": epoch,\n",
    "                    \"lr\": lr,\n",
    "                }\n",
    "                tqdm_epoch.set_postfix(loss=val_loss)\n",
    "\n",
    "                if lowest_validation_loss is None or val_loss < lowest_validation_loss:\n",
    "                    lowest_validation_loss = val_loss\n",
    "                    best_val_epoch = epoch\n",
    "\n",
    "                    model_path = logging_dir / Path(\"models\")\n",
    "                    model_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "                    best_model_path = model_path / f\"{model_name}{epoch}.pt\"\n",
    "                    logger.info(f\"Saving best model to: {best_model_path}\")\n",
    "                    torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "                # reset training logging\n",
    "                total_eo_train_loss = 0.0\n",
    "                num_updates_being_captured = 0\n",
    "                train_size = 0\n",
    "                num_validations += 1\n",
    "\n",
    "                # if wandb_enabled:\n",
    "                #     model.eval()\n",
    "                #     for title, plot in plot_predictions(model):\n",
    "                #         to_log[title] = plot\n",
    "                #     wandb.log(to_log)\n",
    "                #     plt.close(\"all\")\n",
    "\n",
    "                model.train()\n",
    "\n",
    "logger.info(f\"Done training, best model saved to {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1dd8f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
